{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxTzYcAZOTpzyYxF41YAyM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisha1365/Hands-on-NLP/blob/main/Text_Summarization_Cosine_Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Summarization - Cosine Similarity"
      ],
      "metadata": {
        "id": "VlAOmX6B-m7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the enviroment"
      ],
      "metadata": {
        "id": "SGJEvhkL-rlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk \n",
        "import string\n",
        "import numpy as np\n",
        "import networkx as nx #graph\n",
        "from nltk.cluster.util import cosine_distance"
      ],
      "metadata": {
        "id": "bUnwtuUu-wPM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUbKxp7K-3wU",
        "outputId": "d094b838-1ad9-49c9-e9cb-0fa5606d4b29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "print(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fomUvZaI_AP9",
        "outputId": "8cfd1d00-ade9-4c93-c4a6-d7c2a7ba081b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  formatted_text = text.lower()\n",
        "  tokens = []\n",
        "  for token in nltk.word_tokenize(formatted_text):\n",
        "    tokens.append(token)\n",
        "  tokens = [word for word in tokens if word not in stopwords and word not in string.punctuation]\n",
        "  formatted_text = ' '.join(element for element in tokens)\n",
        "\n",
        "  return formatted_text"
      ],
      "metadata": {
        "id": "HKkTUghC_9Cy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_text = \"\"\"Artifical intelligence is human like intelligence.\n",
        "                  It is the study of intelligent artifical agents.\n",
        "                  Science and engineering to produce intelligent machines.\n",
        "                  Solve problems and have intelligence.\n",
        "                  Related to intelligent behavior.\n",
        "                  Developing of resoning machines.\n",
        "                  Learn from mistakes and successes.\n",
        "                  Artifical intelligence is related to reasoning in everyday situations.\"\"\"\n",
        "original_text = re.sub(r'\\s+', ' ', original_text)\n",
        "original_text                  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0XNrOjnoAnZG",
        "outputId": "ebefe971-737c-4082-f600-e44e3888b76d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Artifical intelligence is human like intelligence. It is the study of intelligent artifical agents. Science and engineering to produce intelligent machines. Solve problems and have intelligence. Related to intelligent behavior. Developing of resoning machines. Learn from mistakes and successes. Artifical intelligence is related to reasoning in everyday situations.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to calculate similairty between sentences"
      ],
      "metadata": {
        "id": "_aPjfkjnB04B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_sentences = [sentence for sentence in nltk.sent_tokenize(original_text)]\n",
        "original_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYJfou4NByOJ",
        "outputId": "427bf6c0-b7ed-4dee-b39f-010ed048ec59"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Artifical intelligence is human like intelligence.',\n",
              " 'It is the study of intelligent artifical agents.',\n",
              " 'Science and engineering to produce intelligent machines.',\n",
              " 'Solve problems and have intelligence.',\n",
              " 'Related to intelligent behavior.',\n",
              " 'Developing of resoning machines.',\n",
              " 'Learn from mistakes and successes.',\n",
              " 'Artifical intelligence is related to reasoning in everyday situations.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_sentences = [preprocess(original_sentence) for original_sentence in original_sentences]\n",
        "formatted_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhUEwB96Cexn",
        "outputId": "ecbecee9-9531-4f85-bbbf-fff2afcafce0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artifical intelligence human like intelligence',\n",
              " 'study intelligent artifical agents',\n",
              " 'science engineering produce intelligent machines',\n",
              " 'solve problems intelligence',\n",
              " 'related intelligent behavior',\n",
              " 'developing resoning machines',\n",
              " 'learn mistakes successes',\n",
              " 'artifical intelligence related reasoning everyday situations']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_sentence_similarity(sentence1, sentence2):\n",
        "  words1 = [word for word in nltk.word_tokenize(sentence1)]\n",
        "  words2 = [word for word in nltk.word_tokenize(sentence2)]\n",
        "  #print(words1)\n",
        "  #print(words2)\n",
        "\n",
        "  all_words = list(set(words1 + words2))\n",
        "  #print(all_words)\n",
        "\n",
        "  vector1 = [0] * len(all_words)\n",
        "  vector2 = [0] * len(all_words)\n",
        "  #print(vector1)\n",
        "  #print(vector2)\n",
        "\n",
        "  for word in words1: #Bag of words\n",
        "    #print(word)\n",
        "    vector1[all_words.index(word)] += 1\n",
        "  for word in words2:\n",
        "    vector2[all_words.index(word)]  += 1\n",
        "\n",
        "  #print(vector1)  \n",
        "  #print(vector2)\n",
        "\n",
        "  return 1 - cosine_distance(vector1, vector2)"
      ],
      "metadata": {
        "id": "HOi9lbQYCvT5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_sentence_similarity(formatted_sentences[0], formatted_sentences[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUNzG0tYDNOO",
        "outputId": "f62bcf5c-edb1-47a1-f1de-5b8514f36fdc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = ['human', 'intelligence', 'intelligent', 'study', 'artifical', 'like', 'agents']\n",
        "test.index('study')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNJV35e9IGrb",
        "outputId": "92f8fa5c-d60d-4153-ea3f-a6c2c723ff95"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gbyGpc-aO6_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Nf9txWghO69p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similarity Matrix\n",
        "\n",
        "*   List item\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "*   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "CpgffZplLJ1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_similarity_matrix(sentences):\n",
        "  similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "  #print(similarity_matrix)\n",
        "  for i in range(len(sentences)):\n",
        "    for j in range(len(sentences)):\n",
        "      if i == j:\n",
        "        continue\n",
        "      similarity_matrix[i][j] = calculate_sentence_similarity(sentences[i], sentences[j])\n",
        "    return similarity_matrix     \n",
        "\n",
        "      "
      ],
      "metadata": {
        "id": "r-VCbhumLeXh"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_similarity_matrix(formatted_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_gFdKddDgMk",
        "outputId": "4a4b1f03-c906-4b53-d78c-4a6ffc201002"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.18898224, 0.        , 0.43643578, 0.        ,\n",
              "        0.        , 0.        , 0.46291005],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Atcl_UDwL7iW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}